<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>UnifyMB.Source_Code.AgilentUnify API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>UnifyMB.Source_Code.AgilentUnify</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import csv
import os.path
import errno
import xlsxwriter


class AgilentUnify:
    &#34;&#34;&#34;Converts Agilent csv data to the Unified Excel Format. Handles two different types of .csv outputs.

    Attributes
    ----------
    csv_file_in_list_of_list_format : list(list)
        csv file to be converted in a list of lists.
    csv_file_in_list_of_list_format_condensed : list(list)
        csv file to be converted in a list of lists. Any extra fields not required are removed.
    required_fields_index_dictionary : dict
        dictionary of required file fields, and their indexes. 0&#39;s are placeholders, indexes are found later.
        relevant to the newer ICP/MS.
    required_fields_index_dictionary_old_icp : dict
        dictionary of required file fields, and their indexes. 0&#39;s are placeholders, indexes are found later.
        relevant to the older ICP/MS.
    main_file_name : string
        the name of the excel file to be generated. Same as the batch name you&#39;d use for the TargetLynx file.
    &#34;&#34;&#34;

    def __init__(self, csv_file_in_list_of_list_format):
        &#34;&#34;&#34;
        Parameters
        ----------
        csv_file_in_list_of_list_format : list(list)
            csv file to be converted in a list of lists.
        &#34;&#34;&#34;
        self.csv_file_in_list_of_list_format = csv_file_in_list_of_list_format
        self.csv_file_in_list_of_list_format_condensed = [[&#39;data source&#39;,
                                                           &#39;filename&#39;,
                                                           &#39;create date&#39;,
                                                           &#39;create time&#39;,
                                                           &#39;sample name&#39;,
                                                           &#39;sample type&#39;,
                                                           &#39;analyte name&#39;,
                                                           &#39;analyte concentration&#39;,
                                                           &#39;percent recovery&#39;]]
        self.required_fields_index_dictionary = {&#39;Sample Name&#39;: 0,
                                                 &#39;Sample Type&#39;: 0,
                                                 &#39;Date and Time Acquired&#39;: 0,
                                                 &#39;Data File Name&#39;: 0,
                                                 &#39;Batch Name&#39;: 0,
                                                 &#39;Analyte&#39;: 0,
                                                 &#39;Mass&#39;: 0,
                                                 &#39;Concentration&#39;: 0,
                                                 &#39;Units&#39;: 0,
                                                 &#39;Tune Step&#39;: 0,
                                                 }
        self.required_fields_index_dictionary_old_icp = {&#39;Solution Label&#39;: 0,
                                                         &#39;Type&#39;: 0,
                                                         &#39;Date Time&#39;: 0,
                                                         }
        self.main_file_name = &#34;&#34;

    def agilent_unify_controller(self, old_icp=False):
        &#34;&#34;&#34;The main controller function for AgilentUnify.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output.
            &#34;&#34;&#34;
        if old_icp:
            self.find_indexes_of_required_fields(old_icp)
            self.create_condensed_csv_file_with_only_relevant_fields(old_icp)
        else:
            self.find_indexes_of_required_fields()
            self.create_condensed_csv_file_with_only_relevant_fields()
        self.generate_excel_files()
        # have the option of generating excel files with xlsxwriter, can format somewhat
        # or make un-formatted csv files.
        # self.generate_csv_files()

    def find_indexes_of_required_fields(self, old_icp=False):
        &#34;&#34;&#34;finds the indexes of the fields we need to create our unified excel format.

        This is somewhat unnecessary, because with Agilent instruments, we can always trim fields we don&#39;t need, and
        we can put fields in whatever order we want, so we could in theory already know these indexes. However, having
        this function in place allows us to be lazy - we don&#39;t need to care about the order of fields, and we can ignore
        any extra fields.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output.
        &#34;&#34;&#34;
        if old_icp:
            required_field_index_counter = 0
            for item in self.csv_file_in_list_of_list_format[0]:
                if item in self.required_fields_index_dictionary_old_icp.keys():
                    # then it is a required field
                    # add the index we are at to the dictionary
                    self.required_fields_index_dictionary_old_icp[item] = required_field_index_counter
                required_field_index_counter += 1
        else:
            required_field_index_counter = 0
            for item in self.csv_file_in_list_of_list_format[0]:
                if item in self.required_fields_index_dictionary.keys():
                    # then it is a required field
                    # add the index we are at to the dictionary
                    self.required_fields_index_dictionary[item] = required_field_index_counter
                required_field_index_counter += 1

    def create_condensed_csv_file_with_only_relevant_fields(self, old_icp=False):
        &#34;&#34;&#34;takes only the required fields from the full csv file, and creates a condensed list of lists.

        older ICP/MS as far as I can tell won&#39;t provide one analyte per line, will only do one sample per line,
        with each analyte given as a field. We handle this by iterating over the data part of the sample line, and
        copying the sample data each time to create analyte lines.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output. &#34;&#34;&#34;
        if old_icp:
            # from 6 on, it&#39;s just data
            analytes_list = self.csv_file_in_list_of_list_format[0][6:]
            for item in self.csv_file_in_list_of_list_format[1:]:
                # have to use split because old ICP doesn&#39;t add 0&#39;s to the start of single digit day numbers
                sample_date_and_time = item[self.required_fields_index_dictionary_old_icp[&#39;Date Time&#39;]].split(&#34; &#34;)
                sample_date = sample_date_and_time[0]
                sample_time = sample_date_and_time[1] + &#34; &#34; + sample_date_and_time[2]
                if len(self.main_file_name) &gt; 0:
                    pass
                else:
                    # putting in a placeholder file name. As of right now, no way to carry through the filename. I&#39;m
                    # sure it&#39;s an option in the software output settings, will figure out later. (22June21)
                    self.main_file_name = &#34;Harry_icp_&#34; + sample_date[0]
                analyte_counter = 6
                for analyte in analytes_list:
                    # iterating through the analytes, creating a new line for each one.
                    condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                                      &#39;no data file provided&#39;,
                                      sample_date,
                                      sample_time,
                                      item[self.required_fields_index_dictionary_old_icp[&#39;Solution Label&#39;]],
                                      item[self.required_fields_index_dictionary_old_icp[&#39;Type&#39;]],
                                      analyte,
                                      item[analyte_counter],
                                      &#34; &#34;]
                    self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
                    analyte_counter += 1
        else:
            # much more straightforward, because each line is an analyte, and I&#39;ve already pretty much selected
            # the fields that I want.
            for item in self.csv_file_in_list_of_list_format[1:]:
                # instrument runs in a bunch of different gas modes, and provides data for each analyte in each mode
                # generally one is better/ more accurate/ more reliable. Maybe will filter out some of these
                # in the future for a less cluttered file. (22June21)
                if item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;1&#39;:
                    tune_step = &#39;no gas&#39;
                elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;2&#39;:
                    tune_step = &#39;H&#39;
                elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;3&#39;:
                    tune_step = &#39;He&#39;
                else:
                    tune_step = &#39;not found&#39;
                # can do this because new ICP software adds a leading 0 to single digit numbers
                sample_date = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][0:10]
                sample_time = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][11:]
                analyte_name = str(item[self.required_fields_index_dictionary[&#39;Analyte&#39;]] + &#39; &#39; +
                                   item[self.required_fields_index_dictionary[&#39;Mass&#39;]] + &#39; [&#39; +
                                   tune_step + &#39;]&#39;
                                   )
                condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                                  item[self.required_fields_index_dictionary[&#39;Data File Name&#39;]],
                                  sample_date,
                                  sample_time,
                                  item[self.required_fields_index_dictionary[&#39;Sample Name&#39;]],
                                  item[self.required_fields_index_dictionary[&#39;Sample Type&#39;]],
                                  analyte_name,
                                  item[self.required_fields_index_dictionary[&#39;Concentration&#39;]],
                                  &#34; &#34;]
                self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
            # could do this better, getting the main file name from the first item (individual data file name) minus
            # the last 3 numbers
            self.main_file_name = self.csv_file_in_list_of_list_format[1][5][:-2]

    def generate_excel_files(self):
        &#34;&#34;&#34;generates excel file versions of the unified excel format, using xlsxwriter.

        allows us to add formatting to the file produced, which we can&#39;t do with the .csv version. the formats
        denote shared fields - all rows in the file will have the same values in header_cell_format_1 cells,
        all rows in a sample will have the same values in header_cell_format_2 cells, and the cells with
        header_format_3 change each line. &#34;&#34;&#34;

        target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
        batch_name = str(self.main_file_name)
        filename = target[:-1] + batch_name + &#39;.xlsx&#39;
        workbook = xlsxwriter.Workbook(filename)
        worksheet = workbook.add_worksheet()
        # set column width
        worksheet.set_column(&#39;A:A&#39;, 40)
        worksheet.set_column(&#39;B:I&#39;, 20)
        # header format for the first two columns
        header_cell_format_1 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#2321a7&#39;})
        header_cell_format_2 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#3330db&#39;})
        header_cell_format_3 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;black&#39;, &#39;bg_color&#39;: &#39;#29abdc&#39;})
        # helps with the editing to change the color of each second line
        odd_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#c7d6db&#34;})
        even_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#e9edef&#34;})
        row = 0
        for item in self.csv_file_in_list_of_list_format_condensed:
            if row == 0:
                worksheet.write(row, 0, item[0], header_cell_format_1)
                worksheet.write(row, 1, item[1], header_cell_format_2)
                worksheet.write(row, 2, item[2], header_cell_format_2)
                worksheet.write(row, 3, item[3], header_cell_format_2)
                worksheet.write(row, 4, item[4], header_cell_format_2)
                worksheet.write(row, 5, item[5], header_cell_format_2)
                worksheet.write(row, 6, item[6], header_cell_format_3)
                worksheet.write(row, 7, item[7], header_cell_format_3)
                worksheet.write(row, 8, item[8], header_cell_format_3)
            else:
                if row % 2 == 0:
                    worksheet.write(row, 0, item[0], even_sample_format)
                    worksheet.write(row, 1, item[1], even_sample_format)
                    worksheet.write(row, 2, item[2], even_sample_format)
                    worksheet.write(row, 3, item[3], even_sample_format)
                    worksheet.write(row, 4, item[4], even_sample_format)
                    worksheet.write(row, 5, item[5], even_sample_format)
                    worksheet.write(row, 6, item[6], even_sample_format)
                    worksheet.write(row, 7, item[7], even_sample_format)
                    worksheet.write(row, 8, item[8], even_sample_format)
                else:
                    worksheet.write(row, 0, item[0], odd_sample_format)
                    worksheet.write(row, 1, item[1], odd_sample_format)
                    worksheet.write(row, 2, item[2], odd_sample_format)
                    worksheet.write(row, 3, item[3], odd_sample_format)
                    worksheet.write(row, 4, item[4], odd_sample_format)
                    worksheet.write(row, 5, item[5], odd_sample_format)
                    worksheet.write(row, 6, item[6], odd_sample_format)
                    worksheet.write(row, 7, item[7], odd_sample_format)
                    worksheet.write(row, 8, item[8], odd_sample_format)

            row += 1
        workbook.close()

    def generate_csv_files(self):
        &#34;&#34;&#34;generates csv file versions of the unified excel format, using python&#39;s built in csv library.

        files generated have no formatting. Can use generate_excel_files, which comes with visual formatting.&#34;&#34;&#34;

        target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
        try:
            batch_name = str(self.main_file_name)
            filename = target[:-1] + batch_name + &#39;.csv&#39;
            filename = filename.replace(&#39;/&#39;, &#39;-&#39;)
            with self.safe_open_w(filename) as f:
                csv_writer = csv.writer(f)
                for item in self.csv_file_in_list_of_list_format_condensed:
                    csv_writer.writerow(item)
        except OSError:
            pass

    def mkdir_p(self, path):
        &#34;&#34;&#34;tries to make the directory.&#34;&#34;&#34;

        try:
            os.makedirs(path)
        except OSError as exc:  # Python &gt;2.5
            if exc.errno == errno.EEXIST and os.path.isdir(path):
                pass
            else:
                raise

    def safe_open_w(self, path):
        &#34;&#34;&#34; Open &#34;path&#34; for writing, creating any parent directories as needed. &#34;&#34;&#34;

        self.mkdir_p(os.path.dirname(path))
        return open(path, &#39;w&#39;, newline=&#39;&#39;)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify"><code class="flex name class">
<span>class <span class="ident">AgilentUnify</span></span>
<span>(</span><span>csv_file_in_list_of_list_format)</span>
</code></dt>
<dd>
<div class="desc"><p>Converts Agilent csv data to the Unified Excel Format. Handles two different types of .csv outputs.</p>
<h2 id="attributes">Attributes</h2>
<dl>
<dt><strong><code>csv_file_in_list_of_list_format</code></strong> :&ensp;<code>list(list)</code></dt>
<dd>csv file to be converted in a list of lists.</dd>
<dt><strong><code>csv_file_in_list_of_list_format_condensed</code></strong> :&ensp;<code>list(list)</code></dt>
<dd>csv file to be converted in a list of lists. Any extra fields not required are removed.</dd>
<dt><strong><code>required_fields_index_dictionary</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary of required file fields, and their indexes. 0's are placeholders, indexes are found later.
relevant to the newer ICP/MS.</dd>
<dt><strong><code>required_fields_index_dictionary_old_icp</code></strong> :&ensp;<code>dict</code></dt>
<dd>dictionary of required file fields, and their indexes. 0's are placeholders, indexes are found later.
relevant to the older ICP/MS.</dd>
<dt><strong><code>main_file_name</code></strong> :&ensp;<code>string</code></dt>
<dd>the name of the excel file to be generated. Same as the batch name you'd use for the TargetLynx file.</dd>
</dl>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>csv_file_in_list_of_list_format</code></strong> :&ensp;<code>list(list)</code></dt>
<dd>csv file to be converted in a list of lists.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class AgilentUnify:
    &#34;&#34;&#34;Converts Agilent csv data to the Unified Excel Format. Handles two different types of .csv outputs.

    Attributes
    ----------
    csv_file_in_list_of_list_format : list(list)
        csv file to be converted in a list of lists.
    csv_file_in_list_of_list_format_condensed : list(list)
        csv file to be converted in a list of lists. Any extra fields not required are removed.
    required_fields_index_dictionary : dict
        dictionary of required file fields, and their indexes. 0&#39;s are placeholders, indexes are found later.
        relevant to the newer ICP/MS.
    required_fields_index_dictionary_old_icp : dict
        dictionary of required file fields, and their indexes. 0&#39;s are placeholders, indexes are found later.
        relevant to the older ICP/MS.
    main_file_name : string
        the name of the excel file to be generated. Same as the batch name you&#39;d use for the TargetLynx file.
    &#34;&#34;&#34;

    def __init__(self, csv_file_in_list_of_list_format):
        &#34;&#34;&#34;
        Parameters
        ----------
        csv_file_in_list_of_list_format : list(list)
            csv file to be converted in a list of lists.
        &#34;&#34;&#34;
        self.csv_file_in_list_of_list_format = csv_file_in_list_of_list_format
        self.csv_file_in_list_of_list_format_condensed = [[&#39;data source&#39;,
                                                           &#39;filename&#39;,
                                                           &#39;create date&#39;,
                                                           &#39;create time&#39;,
                                                           &#39;sample name&#39;,
                                                           &#39;sample type&#39;,
                                                           &#39;analyte name&#39;,
                                                           &#39;analyte concentration&#39;,
                                                           &#39;percent recovery&#39;]]
        self.required_fields_index_dictionary = {&#39;Sample Name&#39;: 0,
                                                 &#39;Sample Type&#39;: 0,
                                                 &#39;Date and Time Acquired&#39;: 0,
                                                 &#39;Data File Name&#39;: 0,
                                                 &#39;Batch Name&#39;: 0,
                                                 &#39;Analyte&#39;: 0,
                                                 &#39;Mass&#39;: 0,
                                                 &#39;Concentration&#39;: 0,
                                                 &#39;Units&#39;: 0,
                                                 &#39;Tune Step&#39;: 0,
                                                 }
        self.required_fields_index_dictionary_old_icp = {&#39;Solution Label&#39;: 0,
                                                         &#39;Type&#39;: 0,
                                                         &#39;Date Time&#39;: 0,
                                                         }
        self.main_file_name = &#34;&#34;

    def agilent_unify_controller(self, old_icp=False):
        &#34;&#34;&#34;The main controller function for AgilentUnify.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output.
            &#34;&#34;&#34;
        if old_icp:
            self.find_indexes_of_required_fields(old_icp)
            self.create_condensed_csv_file_with_only_relevant_fields(old_icp)
        else:
            self.find_indexes_of_required_fields()
            self.create_condensed_csv_file_with_only_relevant_fields()
        self.generate_excel_files()
        # have the option of generating excel files with xlsxwriter, can format somewhat
        # or make un-formatted csv files.
        # self.generate_csv_files()

    def find_indexes_of_required_fields(self, old_icp=False):
        &#34;&#34;&#34;finds the indexes of the fields we need to create our unified excel format.

        This is somewhat unnecessary, because with Agilent instruments, we can always trim fields we don&#39;t need, and
        we can put fields in whatever order we want, so we could in theory already know these indexes. However, having
        this function in place allows us to be lazy - we don&#39;t need to care about the order of fields, and we can ignore
        any extra fields.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output.
        &#34;&#34;&#34;
        if old_icp:
            required_field_index_counter = 0
            for item in self.csv_file_in_list_of_list_format[0]:
                if item in self.required_fields_index_dictionary_old_icp.keys():
                    # then it is a required field
                    # add the index we are at to the dictionary
                    self.required_fields_index_dictionary_old_icp[item] = required_field_index_counter
                required_field_index_counter += 1
        else:
            required_field_index_counter = 0
            for item in self.csv_file_in_list_of_list_format[0]:
                if item in self.required_fields_index_dictionary.keys():
                    # then it is a required field
                    # add the index we are at to the dictionary
                    self.required_fields_index_dictionary[item] = required_field_index_counter
                required_field_index_counter += 1

    def create_condensed_csv_file_with_only_relevant_fields(self, old_icp=False):
        &#34;&#34;&#34;takes only the required fields from the full csv file, and creates a condensed list of lists.

        older ICP/MS as far as I can tell won&#39;t provide one analyte per line, will only do one sample per line,
        with each analyte given as a field. We handle this by iterating over the data part of the sample line, and
        copying the sample data each time to create analyte lines.

        Parameters
        ----------
        old_icp=False
            True if we are handling old ICP output. &#34;&#34;&#34;
        if old_icp:
            # from 6 on, it&#39;s just data
            analytes_list = self.csv_file_in_list_of_list_format[0][6:]
            for item in self.csv_file_in_list_of_list_format[1:]:
                # have to use split because old ICP doesn&#39;t add 0&#39;s to the start of single digit day numbers
                sample_date_and_time = item[self.required_fields_index_dictionary_old_icp[&#39;Date Time&#39;]].split(&#34; &#34;)
                sample_date = sample_date_and_time[0]
                sample_time = sample_date_and_time[1] + &#34; &#34; + sample_date_and_time[2]
                if len(self.main_file_name) &gt; 0:
                    pass
                else:
                    # putting in a placeholder file name. As of right now, no way to carry through the filename. I&#39;m
                    # sure it&#39;s an option in the software output settings, will figure out later. (22June21)
                    self.main_file_name = &#34;Harry_icp_&#34; + sample_date[0]
                analyte_counter = 6
                for analyte in analytes_list:
                    # iterating through the analytes, creating a new line for each one.
                    condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                                      &#39;no data file provided&#39;,
                                      sample_date,
                                      sample_time,
                                      item[self.required_fields_index_dictionary_old_icp[&#39;Solution Label&#39;]],
                                      item[self.required_fields_index_dictionary_old_icp[&#39;Type&#39;]],
                                      analyte,
                                      item[analyte_counter],
                                      &#34; &#34;]
                    self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
                    analyte_counter += 1
        else:
            # much more straightforward, because each line is an analyte, and I&#39;ve already pretty much selected
            # the fields that I want.
            for item in self.csv_file_in_list_of_list_format[1:]:
                # instrument runs in a bunch of different gas modes, and provides data for each analyte in each mode
                # generally one is better/ more accurate/ more reliable. Maybe will filter out some of these
                # in the future for a less cluttered file. (22June21)
                if item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;1&#39;:
                    tune_step = &#39;no gas&#39;
                elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;2&#39;:
                    tune_step = &#39;H&#39;
                elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;3&#39;:
                    tune_step = &#39;He&#39;
                else:
                    tune_step = &#39;not found&#39;
                # can do this because new ICP software adds a leading 0 to single digit numbers
                sample_date = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][0:10]
                sample_time = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][11:]
                analyte_name = str(item[self.required_fields_index_dictionary[&#39;Analyte&#39;]] + &#39; &#39; +
                                   item[self.required_fields_index_dictionary[&#39;Mass&#39;]] + &#39; [&#39; +
                                   tune_step + &#39;]&#39;
                                   )
                condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                                  item[self.required_fields_index_dictionary[&#39;Data File Name&#39;]],
                                  sample_date,
                                  sample_time,
                                  item[self.required_fields_index_dictionary[&#39;Sample Name&#39;]],
                                  item[self.required_fields_index_dictionary[&#39;Sample Type&#39;]],
                                  analyte_name,
                                  item[self.required_fields_index_dictionary[&#39;Concentration&#39;]],
                                  &#34; &#34;]
                self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
            # could do this better, getting the main file name from the first item (individual data file name) minus
            # the last 3 numbers
            self.main_file_name = self.csv_file_in_list_of_list_format[1][5][:-2]

    def generate_excel_files(self):
        &#34;&#34;&#34;generates excel file versions of the unified excel format, using xlsxwriter.

        allows us to add formatting to the file produced, which we can&#39;t do with the .csv version. the formats
        denote shared fields - all rows in the file will have the same values in header_cell_format_1 cells,
        all rows in a sample will have the same values in header_cell_format_2 cells, and the cells with
        header_format_3 change each line. &#34;&#34;&#34;

        target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
        batch_name = str(self.main_file_name)
        filename = target[:-1] + batch_name + &#39;.xlsx&#39;
        workbook = xlsxwriter.Workbook(filename)
        worksheet = workbook.add_worksheet()
        # set column width
        worksheet.set_column(&#39;A:A&#39;, 40)
        worksheet.set_column(&#39;B:I&#39;, 20)
        # header format for the first two columns
        header_cell_format_1 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#2321a7&#39;})
        header_cell_format_2 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#3330db&#39;})
        header_cell_format_3 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;black&#39;, &#39;bg_color&#39;: &#39;#29abdc&#39;})
        # helps with the editing to change the color of each second line
        odd_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#c7d6db&#34;})
        even_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#e9edef&#34;})
        row = 0
        for item in self.csv_file_in_list_of_list_format_condensed:
            if row == 0:
                worksheet.write(row, 0, item[0], header_cell_format_1)
                worksheet.write(row, 1, item[1], header_cell_format_2)
                worksheet.write(row, 2, item[2], header_cell_format_2)
                worksheet.write(row, 3, item[3], header_cell_format_2)
                worksheet.write(row, 4, item[4], header_cell_format_2)
                worksheet.write(row, 5, item[5], header_cell_format_2)
                worksheet.write(row, 6, item[6], header_cell_format_3)
                worksheet.write(row, 7, item[7], header_cell_format_3)
                worksheet.write(row, 8, item[8], header_cell_format_3)
            else:
                if row % 2 == 0:
                    worksheet.write(row, 0, item[0], even_sample_format)
                    worksheet.write(row, 1, item[1], even_sample_format)
                    worksheet.write(row, 2, item[2], even_sample_format)
                    worksheet.write(row, 3, item[3], even_sample_format)
                    worksheet.write(row, 4, item[4], even_sample_format)
                    worksheet.write(row, 5, item[5], even_sample_format)
                    worksheet.write(row, 6, item[6], even_sample_format)
                    worksheet.write(row, 7, item[7], even_sample_format)
                    worksheet.write(row, 8, item[8], even_sample_format)
                else:
                    worksheet.write(row, 0, item[0], odd_sample_format)
                    worksheet.write(row, 1, item[1], odd_sample_format)
                    worksheet.write(row, 2, item[2], odd_sample_format)
                    worksheet.write(row, 3, item[3], odd_sample_format)
                    worksheet.write(row, 4, item[4], odd_sample_format)
                    worksheet.write(row, 5, item[5], odd_sample_format)
                    worksheet.write(row, 6, item[6], odd_sample_format)
                    worksheet.write(row, 7, item[7], odd_sample_format)
                    worksheet.write(row, 8, item[8], odd_sample_format)

            row += 1
        workbook.close()

    def generate_csv_files(self):
        &#34;&#34;&#34;generates csv file versions of the unified excel format, using python&#39;s built in csv library.

        files generated have no formatting. Can use generate_excel_files, which comes with visual formatting.&#34;&#34;&#34;

        target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
        try:
            batch_name = str(self.main_file_name)
            filename = target[:-1] + batch_name + &#39;.csv&#39;
            filename = filename.replace(&#39;/&#39;, &#39;-&#39;)
            with self.safe_open_w(filename) as f:
                csv_writer = csv.writer(f)
                for item in self.csv_file_in_list_of_list_format_condensed:
                    csv_writer.writerow(item)
        except OSError:
            pass

    def mkdir_p(self, path):
        &#34;&#34;&#34;tries to make the directory.&#34;&#34;&#34;

        try:
            os.makedirs(path)
        except OSError as exc:  # Python &gt;2.5
            if exc.errno == errno.EEXIST and os.path.isdir(path):
                pass
            else:
                raise

    def safe_open_w(self, path):
        &#34;&#34;&#34; Open &#34;path&#34; for writing, creating any parent directories as needed. &#34;&#34;&#34;

        self.mkdir_p(os.path.dirname(path))
        return open(path, &#39;w&#39;, newline=&#39;&#39;)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.agilent_unify_controller"><code class="name flex">
<span>def <span class="ident">agilent_unify_controller</span></span>(<span>self, old_icp=False)</span>
</code></dt>
<dd>
<div class="desc"><p>The main controller function for AgilentUnify.</p>
<h2 id="parameters">Parameters</h2>
<p>old_icp=False
True if we are handling old ICP output.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def agilent_unify_controller(self, old_icp=False):
    &#34;&#34;&#34;The main controller function for AgilentUnify.

    Parameters
    ----------
    old_icp=False
        True if we are handling old ICP output.
        &#34;&#34;&#34;
    if old_icp:
        self.find_indexes_of_required_fields(old_icp)
        self.create_condensed_csv_file_with_only_relevant_fields(old_icp)
    else:
        self.find_indexes_of_required_fields()
        self.create_condensed_csv_file_with_only_relevant_fields()
    self.generate_excel_files()
    # have the option of generating excel files with xlsxwriter, can format somewhat
    # or make un-formatted csv files.
    # self.generate_csv_files()</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.create_condensed_csv_file_with_only_relevant_fields"><code class="name flex">
<span>def <span class="ident">create_condensed_csv_file_with_only_relevant_fields</span></span>(<span>self, old_icp=False)</span>
</code></dt>
<dd>
<div class="desc"><p>takes only the required fields from the full csv file, and creates a condensed list of lists.</p>
<p>older ICP/MS as far as I can tell won't provide one analyte per line, will only do one sample per line,
with each analyte given as a field. We handle this by iterating over the data part of the sample line, and
copying the sample data each time to create analyte lines.</p>
<h2 id="parameters">Parameters</h2>
<p>old_icp=False
True if we are handling old ICP output.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_condensed_csv_file_with_only_relevant_fields(self, old_icp=False):
    &#34;&#34;&#34;takes only the required fields from the full csv file, and creates a condensed list of lists.

    older ICP/MS as far as I can tell won&#39;t provide one analyte per line, will only do one sample per line,
    with each analyte given as a field. We handle this by iterating over the data part of the sample line, and
    copying the sample data each time to create analyte lines.

    Parameters
    ----------
    old_icp=False
        True if we are handling old ICP output. &#34;&#34;&#34;
    if old_icp:
        # from 6 on, it&#39;s just data
        analytes_list = self.csv_file_in_list_of_list_format[0][6:]
        for item in self.csv_file_in_list_of_list_format[1:]:
            # have to use split because old ICP doesn&#39;t add 0&#39;s to the start of single digit day numbers
            sample_date_and_time = item[self.required_fields_index_dictionary_old_icp[&#39;Date Time&#39;]].split(&#34; &#34;)
            sample_date = sample_date_and_time[0]
            sample_time = sample_date_and_time[1] + &#34; &#34; + sample_date_and_time[2]
            if len(self.main_file_name) &gt; 0:
                pass
            else:
                # putting in a placeholder file name. As of right now, no way to carry through the filename. I&#39;m
                # sure it&#39;s an option in the software output settings, will figure out later. (22June21)
                self.main_file_name = &#34;Harry_icp_&#34; + sample_date[0]
            analyte_counter = 6
            for analyte in analytes_list:
                # iterating through the analytes, creating a new line for each one.
                condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                                  &#39;no data file provided&#39;,
                                  sample_date,
                                  sample_time,
                                  item[self.required_fields_index_dictionary_old_icp[&#39;Solution Label&#39;]],
                                  item[self.required_fields_index_dictionary_old_icp[&#39;Type&#39;]],
                                  analyte,
                                  item[analyte_counter],
                                  &#34; &#34;]
                self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
                analyte_counter += 1
    else:
        # much more straightforward, because each line is an analyte, and I&#39;ve already pretty much selected
        # the fields that I want.
        for item in self.csv_file_in_list_of_list_format[1:]:
            # instrument runs in a bunch of different gas modes, and provides data for each analyte in each mode
            # generally one is better/ more accurate/ more reliable. Maybe will filter out some of these
            # in the future for a less cluttered file. (22June21)
            if item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;1&#39;:
                tune_step = &#39;no gas&#39;
            elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;2&#39;:
                tune_step = &#39;H&#39;
            elif item[self.required_fields_index_dictionary[&#39;Tune Step&#39;]] == &#39;3&#39;:
                tune_step = &#39;He&#39;
            else:
                tune_step = &#39;not found&#39;
            # can do this because new ICP software adds a leading 0 to single digit numbers
            sample_date = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][0:10]
            sample_time = item[self.required_fields_index_dictionary[&#39;Date and Time Acquired&#39;]][11:]
            analyte_name = str(item[self.required_fields_index_dictionary[&#39;Analyte&#39;]] + &#39; &#39; +
                               item[self.required_fields_index_dictionary[&#39;Mass&#39;]] + &#39; [&#39; +
                               tune_step + &#39;]&#39;
                               )
            condensed_line = [&#39;Agilent Instruments: ICP&#39;,
                              item[self.required_fields_index_dictionary[&#39;Data File Name&#39;]],
                              sample_date,
                              sample_time,
                              item[self.required_fields_index_dictionary[&#39;Sample Name&#39;]],
                              item[self.required_fields_index_dictionary[&#39;Sample Type&#39;]],
                              analyte_name,
                              item[self.required_fields_index_dictionary[&#39;Concentration&#39;]],
                              &#34; &#34;]
            self.csv_file_in_list_of_list_format_condensed.append(condensed_line)
        # could do this better, getting the main file name from the first item (individual data file name) minus
        # the last 3 numbers
        self.main_file_name = self.csv_file_in_list_of_list_format[1][5][:-2]</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.find_indexes_of_required_fields"><code class="name flex">
<span>def <span class="ident">find_indexes_of_required_fields</span></span>(<span>self, old_icp=False)</span>
</code></dt>
<dd>
<div class="desc"><p>finds the indexes of the fields we need to create our unified excel format.</p>
<p>This is somewhat unnecessary, because with Agilent instruments, we can always trim fields we don't need, and
we can put fields in whatever order we want, so we could in theory already know these indexes. However, having
this function in place allows us to be lazy - we don't need to care about the order of fields, and we can ignore
any extra fields.</p>
<h2 id="parameters">Parameters</h2>
<p>old_icp=False
True if we are handling old ICP output.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_indexes_of_required_fields(self, old_icp=False):
    &#34;&#34;&#34;finds the indexes of the fields we need to create our unified excel format.

    This is somewhat unnecessary, because with Agilent instruments, we can always trim fields we don&#39;t need, and
    we can put fields in whatever order we want, so we could in theory already know these indexes. However, having
    this function in place allows us to be lazy - we don&#39;t need to care about the order of fields, and we can ignore
    any extra fields.

    Parameters
    ----------
    old_icp=False
        True if we are handling old ICP output.
    &#34;&#34;&#34;
    if old_icp:
        required_field_index_counter = 0
        for item in self.csv_file_in_list_of_list_format[0]:
            if item in self.required_fields_index_dictionary_old_icp.keys():
                # then it is a required field
                # add the index we are at to the dictionary
                self.required_fields_index_dictionary_old_icp[item] = required_field_index_counter
            required_field_index_counter += 1
    else:
        required_field_index_counter = 0
        for item in self.csv_file_in_list_of_list_format[0]:
            if item in self.required_fields_index_dictionary.keys():
                # then it is a required field
                # add the index we are at to the dictionary
                self.required_fields_index_dictionary[item] = required_field_index_counter
            required_field_index_counter += 1</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_csv_files"><code class="name flex">
<span>def <span class="ident">generate_csv_files</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>generates csv file versions of the unified excel format, using python's built in csv library.</p>
<p>files generated have no formatting. Can use generate_excel_files, which comes with visual formatting.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_csv_files(self):
    &#34;&#34;&#34;generates csv file versions of the unified excel format, using python&#39;s built in csv library.

    files generated have no formatting. Can use generate_excel_files, which comes with visual formatting.&#34;&#34;&#34;

    target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
    try:
        batch_name = str(self.main_file_name)
        filename = target[:-1] + batch_name + &#39;.csv&#39;
        filename = filename.replace(&#39;/&#39;, &#39;-&#39;)
        with self.safe_open_w(filename) as f:
            csv_writer = csv.writer(f)
            for item in self.csv_file_in_list_of_list_format_condensed:
                csv_writer.writerow(item)
    except OSError:
        pass</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_excel_files"><code class="name flex">
<span>def <span class="ident">generate_excel_files</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>generates excel file versions of the unified excel format, using xlsxwriter.</p>
<p>allows us to add formatting to the file produced, which we can't do with the .csv version. the formats
denote shared fields - all rows in the file will have the same values in header_cell_format_1 cells,
all rows in a sample will have the same values in header_cell_format_2 cells, and the cells with
header_format_3 change each line.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def generate_excel_files(self):
    &#34;&#34;&#34;generates excel file versions of the unified excel format, using xlsxwriter.

    allows us to add formatting to the file produced, which we can&#39;t do with the .csv version. the formats
    denote shared fields - all rows in the file will have the same values in header_cell_format_1 cells,
    all rows in a sample will have the same values in header_cell_format_2 cells, and the cells with
    header_format_3 change each line. &#34;&#34;&#34;

    target = r&#39;T:\ANALYST WORK FILES\Peter\CrystalMB\UnifiedExcelFiles\ &#39;
    batch_name = str(self.main_file_name)
    filename = target[:-1] + batch_name + &#39;.xlsx&#39;
    workbook = xlsxwriter.Workbook(filename)
    worksheet = workbook.add_worksheet()
    # set column width
    worksheet.set_column(&#39;A:A&#39;, 40)
    worksheet.set_column(&#39;B:I&#39;, 20)
    # header format for the first two columns
    header_cell_format_1 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#2321a7&#39;})
    header_cell_format_2 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;white&#39;, &#39;bg_color&#39;: &#39;#3330db&#39;})
    header_cell_format_3 = workbook.add_format({&#39;bold&#39;: True, &#39;font_color&#39;: &#39;black&#39;, &#39;bg_color&#39;: &#39;#29abdc&#39;})
    # helps with the editing to change the color of each second line
    odd_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#c7d6db&#34;})
    even_sample_format = workbook.add_format({&#39;bg_color&#39;: &#34;#e9edef&#34;})
    row = 0
    for item in self.csv_file_in_list_of_list_format_condensed:
        if row == 0:
            worksheet.write(row, 0, item[0], header_cell_format_1)
            worksheet.write(row, 1, item[1], header_cell_format_2)
            worksheet.write(row, 2, item[2], header_cell_format_2)
            worksheet.write(row, 3, item[3], header_cell_format_2)
            worksheet.write(row, 4, item[4], header_cell_format_2)
            worksheet.write(row, 5, item[5], header_cell_format_2)
            worksheet.write(row, 6, item[6], header_cell_format_3)
            worksheet.write(row, 7, item[7], header_cell_format_3)
            worksheet.write(row, 8, item[8], header_cell_format_3)
        else:
            if row % 2 == 0:
                worksheet.write(row, 0, item[0], even_sample_format)
                worksheet.write(row, 1, item[1], even_sample_format)
                worksheet.write(row, 2, item[2], even_sample_format)
                worksheet.write(row, 3, item[3], even_sample_format)
                worksheet.write(row, 4, item[4], even_sample_format)
                worksheet.write(row, 5, item[5], even_sample_format)
                worksheet.write(row, 6, item[6], even_sample_format)
                worksheet.write(row, 7, item[7], even_sample_format)
                worksheet.write(row, 8, item[8], even_sample_format)
            else:
                worksheet.write(row, 0, item[0], odd_sample_format)
                worksheet.write(row, 1, item[1], odd_sample_format)
                worksheet.write(row, 2, item[2], odd_sample_format)
                worksheet.write(row, 3, item[3], odd_sample_format)
                worksheet.write(row, 4, item[4], odd_sample_format)
                worksheet.write(row, 5, item[5], odd_sample_format)
                worksheet.write(row, 6, item[6], odd_sample_format)
                worksheet.write(row, 7, item[7], odd_sample_format)
                worksheet.write(row, 8, item[8], odd_sample_format)

        row += 1
    workbook.close()</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.mkdir_p"><code class="name flex">
<span>def <span class="ident">mkdir_p</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"><p>tries to make the directory.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mkdir_p(self, path):
    &#34;&#34;&#34;tries to make the directory.&#34;&#34;&#34;

    try:
        os.makedirs(path)
    except OSError as exc:  # Python &gt;2.5
        if exc.errno == errno.EEXIST and os.path.isdir(path):
            pass
        else:
            raise</code></pre>
</details>
</dd>
<dt id="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.safe_open_w"><code class="name flex">
<span>def <span class="ident">safe_open_w</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"><p>Open "path" for writing, creating any parent directories as needed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def safe_open_w(self, path):
    &#34;&#34;&#34; Open &#34;path&#34; for writing, creating any parent directories as needed. &#34;&#34;&#34;

    self.mkdir_p(os.path.dirname(path))
    return open(path, &#39;w&#39;, newline=&#39;&#39;)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="UnifyMB.Source_Code" href="index.html">UnifyMB.Source_Code</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify">AgilentUnify</a></code></h4>
<ul class="">
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.agilent_unify_controller" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.agilent_unify_controller">agilent_unify_controller</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.create_condensed_csv_file_with_only_relevant_fields" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.create_condensed_csv_file_with_only_relevant_fields">create_condensed_csv_file_with_only_relevant_fields</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.find_indexes_of_required_fields" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.find_indexes_of_required_fields">find_indexes_of_required_fields</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_csv_files" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_csv_files">generate_csv_files</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_excel_files" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.generate_excel_files">generate_excel_files</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.mkdir_p" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.mkdir_p">mkdir_p</a></code></li>
<li><code><a title="UnifyMB.Source_Code.AgilentUnify.AgilentUnify.safe_open_w" href="#UnifyMB.Source_Code.AgilentUnify.AgilentUnify.safe_open_w">safe_open_w</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>